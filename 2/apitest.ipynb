{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLB244INhP0z"
      },
      "outputs": [],
      "source": [
        "!pip -q install fastapi uvicorn nest_asyncio pyngrok==7.2.0 \"pydantic<3\" joblib scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NGROK_AUTHTOKEN = \"30s47Zrpt0z8JIXJRCLMMklctLS_43GWGBsYeAL5k558po9Xo\"  # 있으면 넣고, 없으면 빈 문자열 유지\n"
      ],
      "metadata": {
        "id": "zpS8ZivShRNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, joblib, json\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "MODEL_PATH = \"/content/model.pkl\"\n",
        "\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "    # ---- 데모용 간이 이진감성 분류기(positive/negative) 학습 ----\n",
        "    texts = [\n",
        "        \"너무 행복하고 기분이 좋아!\", \"정말 만족스러운 경험이었다.\", \"즐겁고 기대돼.\",\n",
        "        \"짜증나고 우울해.\", \"최악이야 다시는 하기 싫어.\", \"불안하고 걱정돼.\"\n",
        "    ]\n",
        "    labels = [\"positive\",\"positive\",\"positive\",\"negative\",\"negative\",\"negative\"]\n",
        "\n",
        "    pipe = Pipeline([\n",
        "        (\"tfidf\", TfidfVectorizer()),\n",
        "        (\"clf\", LogisticRegression(max_iter=200))\n",
        "    ])\n",
        "    pipe.fit(texts, labels)\n",
        "    joblib.dump(pipe, MODEL_PATH)\n",
        "\n",
        "# 로딩(버전 호환 이슈가 있으면 scikit-learn 버전 맞추세요)\n",
        "pipe = joblib.load(MODEL_PATH)\n",
        "\n",
        "# 확률 예측 가능 여부 체크\n",
        "supports_proba = hasattr(pipe, \"predict_proba\")\n",
        "label_classes = None\n",
        "try:\n",
        "    # 대부분의 sklearn 분류기는 classes_ 보유\n",
        "    label_classes = list(pipe.classes_)  # 예: [\"negative\",\"positive\"]\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "print(\"모델 로딩 OK. supports_proba:\", supports_proba, \"classes:\", label_classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPCEfjcshRQb",
        "outputId": "aea299a8-eeb3-41af-cb0e-5372954acca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델 로딩 OK. supports_proba: True classes: [np.str_('negative'), np.str_('positive')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "from fastapi import FastAPI\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from pydantic import BaseModel\n",
        "import uvicorn\n",
        "\n",
        "app = FastAPI(title=\"TextClassifier API\", version=\"1.0.0\", description=\"PKL 모형 기반 문장 분류 API\")\n",
        "# CORS: 필요시 Custom GPT 도메인 허용(여기선 모두 허용)\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"], allow_credentials=True,\n",
        "    allow_methods=[\"*\"], allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "# ------- Request/Response 스키마 -------\n",
        "class PredictRequest(BaseModel):\n",
        "    text: str | None = None\n",
        "    texts: list[str] | None = None  # 배치 요청 지원\n",
        "\n",
        "class PredictResponse(BaseModel):\n",
        "    labels: list[str]\n",
        "    probabilities: list[dict] | None = None  # 각 문장별 {라벨: 확률}\n",
        "\n",
        "# ------- 헬스체크 -------\n",
        "@app.get(\"/health\")\n",
        "def health():\n",
        "    return {\"status\": \"ok\"}\n",
        "\n",
        "# ------- 예측 엔드포인트 -------\n",
        "@app.post(\"/predict\", response_model=PredictResponse)\n",
        "def predict(req: PredictRequest):\n",
        "    # 단문 또는 배치 둘 다 지원\n",
        "    inputs = []\n",
        "    if req.text is not None:\n",
        "        inputs = [req.text]\n",
        "    elif req.texts is not None and len(req.texts) > 0:\n",
        "        inputs = req.texts\n",
        "    else:\n",
        "        return PredictResponse(labels=[], probabilities=[])\n",
        "\n",
        "    preds = pipe.predict(inputs)\n",
        "    labels = [str(p) for p in preds]\n",
        "\n",
        "    probas = None\n",
        "    if supports_proba:\n",
        "        raw = pipe.predict_proba(inputs)  # shape: (n_samples, n_classes)\n",
        "        classes = list(pipe.classes_) if label_classes is None else label_classes\n",
        "        probas = []\n",
        "        for row in raw:\n",
        "            probas.append({cls: float(p) for cls, p in zip(classes, row)})\n",
        "\n",
        "    return PredictResponse(labels=labels, probabilities=probas)\n",
        "\n",
        "# --- Uvicorn을 백그라운드로 기동하는 헬퍼 ---\n",
        "def run_uvicorn():\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000, log_level=\"info\", access_log=False)\n"
      ],
      "metadata": {
        "id": "_kkS5ja-hYeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import threading, time\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# ngrok 준비\n",
        "if NGROK_AUTHTOKEN:\n",
        "    ngrok.set_auth_token(NGROK_AUTHTOKEN)\n",
        "\n",
        "# 기존 터널 정리\n",
        "for t in ngrok.get_tunnels():\n",
        "    ngrok.disconnect(t.public_url)\n",
        "\n",
        "# 새 HTTPS 터널\n",
        "public_tunnel = ngrok.connect(8000, \"http\")\n",
        "public_url = public_tunnel.public_url.replace(\"http://\", \"https://\")  # https로 통일\n",
        "print(\"Public URL:\", public_url)\n",
        "\n",
        "# servers 주입용 OpenAPI 오버라이드\n",
        "from fastapi.openapi.utils import get_openapi\n",
        "\n",
        "def custom_openapi():\n",
        "    if app.openapi_schema:\n",
        "        # 기존에 생성되어 있다면 servers만 바꿔치기\n",
        "        app.openapi_schema[\"servers\"] = [{\"url\": public_url}]\n",
        "        return app.openapi_schema\n",
        "\n",
        "    openapi_schema = get_openapi(\n",
        "        title=app.title,\n",
        "        version=app.version,\n",
        "        description=app.description,\n",
        "        routes=app.routes,\n",
        "    )\n",
        "    openapi_schema[\"servers\"] = [{\"url\": public_url}]\n",
        "    app.openapi_schema = openapi_schema\n",
        "    return app.openapi_schema\n",
        "\n",
        "app.openapi = custom_openapi  # 동적 바인딩\n",
        "\n",
        "# Uvicorn 백그라운드 기동\n",
        "thread = threading.Thread(target=run_uvicorn, daemon=True)\n",
        "thread.start()\n",
        "time.sleep(1.5)  # 서버 부팅 대기\n",
        "\n",
        "print(\"Docs:\", public_url + \"/docs\")\n",
        "print(\"OpenAPI JSON:\", public_url + \"/openapi.json\")\n",
        "print(\"Health:\", public_url + \"/health\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIJKYKWRhYhH",
        "outputId": "78a0e192-c94a-4e1c-bc97-13ac9eb762be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [456]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: https://fb975f3114ba.ngrok.app\n",
            "Docs: https://fb975f3114ba.ngrok.app/docs\n",
            "OpenAPI JSON: https://fb975f3114ba.ngrok.app/openapi.json\n",
            "Health: https://fb975f3114ba.ngrok.app/health\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, json\n",
        "\n",
        "sample = {\"texts\": [\"오늘 정말 행복해!\", \"불안하고 걱정돼.\"]}\n",
        "r = requests.post(public_url + \"/predict\", headers={\"Content-Type\":\"application/json\"}, data=json.dumps(sample))\n",
        "print(r.status_code)\n",
        "print(r.json())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRORzN9jhRVu",
        "outputId": "83bd096f-4f5c-4f0b-bcea-27d5e01ac4dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n",
            "{'labels': ['positive', 'negative'], 'probabilities': [{'negative': 0.4423641294660283, 'positive': 0.5576358705339717}, {'negative': 0.5989509319175137, 'positive': 0.40104906808248625}]}\n"
          ]
        }
      ]
    }
  ]
}