{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#1. 텍스트 데이터 처리"
      ],
      "metadata": {
        "id": "yVjKkCb4_2eL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3hmyq0QphHq"
      },
      "source": [
        "### NLP & Text Mining\n",
        "- 자연어처리: Natural Language Processing\n",
        "- Text Mining: 텍스트 데이터를 자연어 처리 기술로 유용한 정보를 추출하여 분석\n",
        "- 텍스트 마이닝 응용 분야: 분류, 감성 분석, 요약, 군집\n",
        "\n",
        "- 텍스트 자료의 정형화\n",
        " - TDM 또는 DTM\n",
        " - Word2Vec, Doc2Vec 등 임베딩 기법\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UvBMD8nvzbs"
      },
      "source": [
        "- 사용 라이브러리\n",
        " - NLTK(National Language Toolkit for python): 기본 필수 라이브러리, 속도 이슈.\n",
        " - Gensim : 토픽 모델링, 임베딩 등의 기능 제공\n",
        " - Word Colud : 시각화\n",
        " - KoNLPy: 한글처리\n",
        "\n",
        "- NLP 단계\n",
        " - Cleansing: 불필요한 문자/문장부호/수치/태그 등 제거\n",
        " - 토큰(token): 문법적으로 최소 언어요소\n",
        " - 토큰화(Text Toeknization): Corpus로 부터 토큰 추출\n",
        " - Stop word 제거 : 분석에 큰 의미가 없는 단어(a, the, is, will등) 정리\n",
        " - Stemming / Lemmatization : 어근(단어 원형) 추출+단어원형 찾기\n",
        " - N-gram: 개별 단어 각각이 토큰이 되는 경우 문맥적 고려 어려움, N-gram은 연속된 n개의 단어를 하나의 토큰처럼 분리. n개 윈도우로 순서대로 토큰화\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5cGomarZpPH"
      },
      "source": [
        "### 한글 처리\n",
        "- 한국어 처리: 형태소 분석기 Okt(Open Korea Text), 메캅(Mecab), 코모란(Komoran), 한나눔(Hannanum), 꼬꼬마(Kkma)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FBJYcRcl_ae"
      },
      "source": [
        "- 형태소 분석:\n",
        " - KoNLPy는 다음과 같은 다양한 형태소 분석, 태깅 라이브러리를 제공\n",
        "\n",
        " - Hannanum: 한나눔. KAIST Semantic Web Research Center 개발.\n",
        "\n",
        " - http://semanticweb.kaist.ac.kr/hannanum/\n",
        "\n",
        " - Kkma: 꼬꼬마. 서울대학교 IDS(Intelligent Data Systems) 연구실 개발.\n",
        "\n",
        " - http://kkma.snu.ac.kr/\n",
        "\n",
        " - Komoran: 코모란. Shineware에서 개발.\n",
        "\n",
        " - https://github.com/shin285/KOMORAN\n",
        "\n",
        " - Mecab: 메카브. 일본어용 형태소 분석기를 한국어를 사용할 수 있도록 수정.\n",
        "\n",
        " - https://bitbucket.org/eunjeon/mecab-ko\n",
        "\n",
        " - Open Korean Text: 오픈 소스 한국어 분석기. 과거 트위터 형태소 분석기.\n",
        "\n",
        " - https://github.com/open-korean-text/open-korean-text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u780Vl06aFA9",
        "outputId": "10b2cc78-4b31-4238-b1a6-9208c4ec1808"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading JPype1-1.4.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.3/465.3 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.3)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.1)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.1 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLh3AkQvQfA2",
        "outputId": "fa04a8c3-dfb8-4bd2-cdb3-783faefecf5e"
      },
      "source": [
        "from konlpy.tag import Okt\n",
        "okt=Okt()\n",
        "print(okt.morphs(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))\n",
        "# 텍스트를 형태로 단위로 나누는데,이때 각 단어에서 어간을 추출"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['열심히', '코딩', '한', '당신', ',', '연휴', '에는', '여행', '을', '가봐요']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOOsZK_baEQ8",
        "outputId": "efcbe524-6199-4e85-c842-dce06c7672f4"
      },
      "source": [
        "print(okt.pos('열심히 코딩한 당신, 연휴에는 여행을 가봐요'))\n",
        "# 품사추출."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('열심히', 'Adverb'), ('코딩', 'Noun'), ('한', 'Josa'), ('당신', 'Noun'), (',', 'Punctuation'), ('연휴', 'Noun'), ('에는', 'Josa'), ('여행', 'Noun'), ('을', 'Josa'), ('가봐요', 'Verb')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77gyosOhCbL5",
        "outputId": "3e2ce53c-1a5d-422a-f4f8-e78b1519b6e2"
      },
      "source": [
        "print(okt.nouns('열심히 코딩한 당신, 연휴에는 여행을 가봐요'))\n",
        "# 명사추출."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['코딩', '당신', '연휴', '여행']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-_ERx0nfG56"
      },
      "source": [
        "- 1) morphs : 형태소 추출\n",
        "- 2) pos : 품사 태깅\n",
        "- 3) nouns : 명사 추출\n",
        "\n",
        "\n",
        "- Kkma 이용 시"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DXkiL4AfRp3",
        "outputId": "ffc73faa-fb44-4677-b0c8-80e9d8cbd6d8"
      },
      "source": [
        "from konlpy.tag import Kkma\n",
        "kkma=Kkma()\n",
        "print(kkma.morphs(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['열심히', '코딩', '하', 'ㄴ', '당신', ',', '연휴', '에', '는', '여행', '을', '가보', '아요']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oDxkMfvfVQd",
        "outputId": "d9164279-a498-4c86-a7ce-a3cfa1478fa9"
      },
      "source": [
        "print(kkma.pos(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('열심히', 'MAG'), ('코딩', 'NNG'), ('하', 'XSV'), ('ㄴ', 'ETD'), ('당신', 'NP'), (',', 'SP'), ('연휴', 'NNG'), ('에', 'JKM'), ('는', 'JX'), ('여행', 'NNG'), ('을', 'JKO'), ('가보', 'VV'), ('아요', 'EFN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9IgEVII90bRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. 토픽 발견"
      ],
      "metadata": {
        "id": "uh4ho_-eLNIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip setuptools wheel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "m_wW78X2VdW-",
        "outputId": "ba863e2a-e8a6-442f-a2ec-3447f796344e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (75.2.0)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-80.8.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (0.45.1)\n",
            "Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-80.8.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: setuptools, pip\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pip-25.1.1 setuptools-80.8.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "pkg_resources"
                ]
              },
              "id": "0add19dfdf884a9fa16737356386a9c7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfg1_dq5VPYM",
        "outputId": "08fd344f-4ff4-4a77-9b20-e86a1881342f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n",
            "\u001b[2K  Attempting uninstall: numpy\n",
            "\u001b[2K    Found existing installation: numpy 2.0.2\n",
            "\u001b[2K    Uninstalling numpy-2.0.2:\n",
            "\u001b[2K      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[2K  Attempting uninstall: scipy\n",
            "\u001b[2K    Found existing installation: scipy 1.15.3\n",
            "\u001b[2K    Uninstalling scipy-1.15.3:\n",
            "\u001b[2K      Successfully uninstalled scipy-1.15.3\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [gensim]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#이후 세션 재시작 혹은 아래 코드\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "q7YkJAk3YoM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "from konlpy.tag import Okt\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "k9Y6S1BISx1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정규 표현식을 통한 한글 외 문자 제거\n",
        "train_data['articles'] = train_data['articles'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")"
      ],
      "metadata": {
        "id": "yrpRZ6GNkEU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[:5] # 상위 5개 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "14OAJOlIkF48",
        "outputId": "68a67c05-b987-43eb-c418-e32dba333b49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  label                                           articles\n",
              "0           0      0  게티이미지뱅크 콩나물(사진)은 대두를 발아시켜 뿌리를 자라게 한 것이다. 동의보감에...\n",
              "1           1      0  사진 한 장 없이 떠난 일지 스님 불교 현실에 대한 질타 등 생전에 연재했던 글, ...\n",
              "2           2      0  이재익의 아재음악 열전전태관(왼쪽)과 김종진. <한겨레> 자료사진 2018년을 얼마...\n",
              "3           3      0  서울대병원 제공서울대병원은 올해 1월부터 국내에서 독자적으로 개발한 인공지능 기술을...\n",
              "4           4      0  ㆍ2.1㎓ 속도 ‘엑시노스 오토 V9’ㆍ2021년 생산 차량부터 탑재2021년 생산..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-466d0a0a-5385-4e39-aa81-1cbddf407bd0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>label</th>\n",
              "      <th>articles</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>게티이미지뱅크 콩나물(사진)은 대두를 발아시켜 뿌리를 자라게 한 것이다. 동의보감에...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>사진 한 장 없이 떠난 일지 스님 불교 현실에 대한 질타 등 생전에 연재했던 글, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>이재익의 아재음악 열전전태관(왼쪽)과 김종진. &lt;한겨레&gt; 자료사진 2018년을 얼마...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>서울대병원 제공서울대병원은 올해 1월부터 국내에서 독자적으로 개발한 인공지능 기술을...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>ㆍ2.1㎓ 속도 ‘엑시노스 오토 V9’ㆍ2021년 생산 차량부터 탑재2021년 생산...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-466d0a0a-5385-4e39-aa81-1cbddf407bd0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-466d0a0a-5385-4e39-aa81-1cbddf407bd0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-466d0a0a-5385-4e39-aa81-1cbddf407bd0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-bf4bcf14-1068-49d3-8230-d7425cdd44f5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bf4bcf14-1068-49d3-8230-d7425cdd44f5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-bf4bcf14-1068-49d3-8230-d7425cdd44f5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"train_data[:5] # \\uc0c1\\uc704 5\\uac1c \\ucd9c\\ub825\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"articles\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\uc0ac\\uc9c4 \\ud55c \\uc7a5 \\uc5c6\\uc774 \\ub5a0\\ub09c \\uc77c\\uc9c0 \\uc2a4\\ub2d8 \\ubd88\\uad50 \\ud604\\uc2e4\\uc5d0 \\ub300\\ud55c \\uc9c8\\ud0c0 \\ub4f1 \\uc0dd\\uc804\\uc5d0 \\uc5f0\\uc7ac\\ud588\\ub358 \\uae00, \\ucc45\\uc73c\\ub85c \\ubb36\\uc5b4\\uc0ac\\uc9c4 \\ud55c \\uc7a5 \\ub0a8\\uae30\\uc9c0 \\uc54a\\uc558\\ub2e4. \\uc800\\uc11c\\ub294 20\\uc5ec \\uad8c \\ub0a8\\uacbc\\ub2e4. \\uc77c\\uc9c0(\\u4e00\\u6307\\u00b71960~2002) \\uc2a4\\ub2d8 \\uc774\\uc57c\\uae30\\ub2e4.1974\\ub144 \\uc11c\\uc639(1912~2003) \\uc2a4\\ub2d8(\\uc804 \\ubc31\\uc591\\uc0ac \\ubc29\\uc7a5)\\uc744 \\uc740\\uc0ac\\ub85c \\ucd9c\\uac00\\ud55c \\uc77c\\uc9c0 \\uc2a4\\ub2d8\\uc740 \\ud574\\uc778\\uc0ac \\uac15\\uc6d0\\uc744 \\uc878\\uc5c5\\ud558\\uace0 \\uacbd\\ud559\\uacfc \\uc120\\ud559\\uc5d0 \\ub9e4\\uc9c4\\ud558\\uba70 \\ud604\\ub300 \\uc778\\ubb38\\ud559\\uacfc \\ubd88\\uad50\\uc758 \\uc811\\uc810\\uc744 \\ucc3e\\uc73c\\ub824 \\uc560\\uc37c\\ub2e4. 1988\\ub144 \\uc81c1\\ud68c \\ud574\\uc778\\ud559\\uc220\\uc0c1 \\uc218\\uc0c1 \\ub17c\\ubb38 '\\ud604\\ub300 \\uc911\\uacf5(\\u4e2d\\u5171)\\uc758 \\ubd88\\uad50\\uc778\\uc2dd'\\ub3c4 \\uadf8\\ub7f0 \\ub178\\ub825\\uc758 \\ud558\\ub098\\uc600\\ub2e4. \\ub3c4\\ubc18\\u00b7\\ud6c4\\ud559\\ub4e4\\uacfc \\ud65c\\ubc1c\\ud558\\uac8c \\uacbd\\uc804\\uacfc \\uc120\\uc5b4\\ub85d(\\u79aa\\u8a9e\\u9304)\\uc744 \\uc77d\\uace0 \\ubc88\\uc5ed\\ud558\\uace0 \\ucc45\\uc744 \\uc4f0\\ub358 \\uadf8\\ub294 2002\\ub144 \\uc11c\\uc6b8 \\uc218\\uad6d\\uc0ac \\ub0b4 10\\ud3c9 \\uc815\\ub3c4\\uc758 \\ucee8\\ud14c\\uc774\\ub108 \\uc219\\uc18c\\uc5d0\\uc11c \\uc228\\uc9c4 \\ucc44 \\ubc1c\\uacac\\ub410\\ub2e4.\\ucd5c\\uadfc \\ubc1c\\uac04\\ub41c '\\ubd88\\uad50\\uc778\\ubb38\\uc8fc\\uc758\\uc790\\uc758 \\uacbd\\uc804\\uc77d\\uae30'(\\uc5b4\\uc758\\uc6b4\\ud558)\\u3008\\uc0ac\\uc9c4\\u3009\\ub294 \\uc77c\\uc9c0 \\uc2a4\\ub2d8\\uc758 \\ub9c8\\uc9c0\\ub9c9 \\ubc1c\\uc790\\ucde8\\ub2e4. \\uc6d4\\uac04 '\\ubd88\\uad11'\\uc5d0 2000\\ub144 1\\uc6d4\\ubd80\\ud130 24\\uac1c\\uc6d4\\uac04 \\uc5f0\\uc7ac\\ud55c \\uc6d0\\uace0\\ub97c \\ucc45\\uc73c\\ub85c \\uc5ee\\uc5c8\\ub2e4. '\\ubd88\\uad50\\uc5d0\\uc11c \\uae38\\uc744 \\ubb3b\\ub2e4' '\\uc5c5' '\\uacbd\\uc804' '\\uc120(\\u79aa)' '\\ud574\\ud0c8' \\ub4f1 24\\uac00\\uc9c0 \\uc8fc\\uc81c\\ub97c \\uacbd\\uc804\\uc5d0\\uc11c \\ubf51\\uace0 \\uc790\\uc2e0\\uc758 \\ud574\\uc11d\\uc744 \\ubd99\\uc600\\ub2e4.\\uccab\\uba38\\ub9ac, '\\uc99d\\uc77c\\uc544\\ud568\\uacbd' \\uc911 \\\"\\ub098\\ub294 \\uc778\\uac04\\uc758 \\ubab8\\uc73c\\ub85c \\ud0dc\\uc5b4\\ub0ac\\uace0 \\uc778\\uac04\\uc73c\\ub85c \\uc131\\uc7a5\\ud558\\uc600\\uc73c\\uba70 \\uc778\\uac04\\uc73c\\ub85c\\uc11c \\ubd93\\ub2e4\\ub97c \\uc774\\ub8e8\\uc5c8\\ub2e4\\\"\\ub294 \\uad6c\\uc808\\uc5d0 \\ub300\\ud574 \\uc2a4\\ub2d8\\uc740 \\\"\\ubd80\\ucc98\\ub2d8 \\uc2a4\\uc2a4\\ub85c \\uc778\\uac04\\uc784\\uc744 \\uc120\\uc5b8\\ud55c\\ub2e4. \\ubd88\\uad50\\ub294 \\uc2e0(\\u795e)\\uc758 \\uc874\\uc7ac\\ub97c \\uc0c1\\uc815\\ud558\\uac70\\ub098 \\uc2e0\\uc758 \\uc874\\uc7ac\\ub97c \\ub17c\\uc99d\\ud558\\ub294 \\uac83\\uc744 \\ucca0\\ud559\\uc801 \\ubaa9\\ud45c\\ub85c \\uc0bc\\uc9c0 \\uc54a\\ub294\\ub2e4\\\"\\uace0 \\uc815\\uc758\\ud55c\\ub2e4.'\\uc120(\\u79aa)'\\uc5d0 \\uc774\\ub974\\uba74 \\uc80a\\uc740 \\ucd9c\\uac00\\uc790\\uc758 \\ucd94\\uc0c1 \\uac19\\uc740 \\ubb38\\uc81c\\uc758\\uc2dd\\uc744 \\uac10\\ucd94\\uc9c0 \\uc54a\\ub294\\ub2e4. \\\"\\uc624\\ub298 \\uc120(\\u79aa)\\uc740 \\ub9c8\\uce58 \\uc778\\uc2a4\\ud134\\ud2b8\\uc2dd\\ud488\\uc744 \\uac00\\ub4dd \\ucc44\\uc6cc\\ub193\\uace0 \\uc5b8\\uc81c\\ub4e0\\uc9c0 \\ud30c\\ub294 \\uc0ac\\uc0c1\\uc758 24\\uc2dc\\uac04 \\ud3b8\\uc758\\uc810\\uc758 \\ud55c \\uc0c1\\ud488\\ucc98\\ub7fc \\uc5ec\\uaca8\\uc9c4\\ub2e4.\\\" \\\"\\uc120\\uc740 \\ub9cc\\ubcd1\\ud1b5\\uce58\\uc57d\\uc774 \\uc544\\ub2c8\\ub2e4. \\ub300\\uc2b9\\ubd88\\uad50 \\ubcf8\\ub798\\uc758 \\uc9c0\\ud61c\\uc640 \\uc790\\ube44\\ub97c \\ub9dd\\uac01\\ud55c \\uc120\\uc740 \\ubd88\\uad50\\uac00 \\uc544\\ub2c8\\ub77c \\ub3c4\\uad50(\\u9053\\u654e)\\ub2e4.\\\"'\\ud574\\ud0c8'\\uc5d0 \\ub300\\ud574\\uc11c\\ub3c4 '\\ucd94\\uc0c1\\uc801, \\ud604\\uc2e4 \\ucd08\\uc6d4 \\ud639\\uc740 \\ub3c4\\ud53c\\uc801'\\uc778 \\uac83\\uc774 \\uc544\\ub2c8\\ub77c \\ub2e8\\uc5b8\\ud55c\\ub2e4. \\uadf8\\ub294 \\\"\\ubc14\\ub85c \\uc9c0\\uae08 \\uc774 \\uc790\\ub9ac\\uc5d0\\uc11c \\ub2f9\\uc2e0\\uc758 \\ub9c8\\uc74c \\uc0c1\\ud0dc, \\uc695\\uad6c\\uc5d0 \\ub300\\ud574 \\uc0ac\\uc0c9\\ud558\\uace0 \\ud0d0\\uc9c4\\uce58(\\u8caa\\u778b\\u75f4)\\ub85c \\uc624\\uc5fc\\ub418\\uc5b4 \\uc788\\ub294 \\ubd88\\uc21c\\ud55c \\uc5d0\\ub108\\uc9c0\\uc640 \\uac70\\ud488\\uc744 \\uac77\\uc5b4\\ub0b4\\uba74 \\ud574\\ud0c8\\uc740 \\uadf8\\ub807\\uac8c \\ucd94\\uc0c1\\uc801\\uc774\\uac70\\ub098 \\uc2e0\\ube44\\ud55c \\uac83\\ub9cc\\uc774 \\uc544\\ub2c8\\ub77c\\ub294 \\uac83\\uc744 \\uae68\\ub2eb\\uac8c \\ub420 \\uac83\\\"\\uc774\\ub77c\\uace0 \\ub9d0\\ud55c\\ub2e4.\\ucc45\\uc744 \\uc77d\\uc73c\\uba74 \\uadf8\\uc758 \\uc9e7\\uc740 \\uc0b6\\uc774 \\uc548\\ud0c0\\uae5d\\ub2e4. \\ub610 \\uadf8\\uac00 \\uce58\\uc5f4\\ud558\\uac8c \\uace0\\ubbfc\\ud588\\ub358 \\ud55c\\uad6d \\ubd88\\uad50\\uc758 \\ubb38\\uc81c\\uc810\\uacfc \\ubaa8\\uc21c\\uc774 \\uc5bc\\ub9c8\\ub098 \\ud574\\uc18c\\ub410\\ub294\\uc9c0 \\ub3cc\\uc544\\ubcf4\\uac8c \\ub41c\\ub2e4.[\\uae40\\ud55c\\uc218 \\uae30\\uc790 hansu@chosun.com] \\t[\\ub124\\uc774\\ubc84 \\uba54\\uc778\\uc5d0\\uc11c \\uc870\\uc120\\uc77c\\ubcf4 \\ubc1b\\uc544\\ubcf4\\uae30][\\uc870\\uc120\\ub2f7\\ucef4 \\ubc14\\ub85c\\uac00\\uae30][\\uc870\\uc120\\uc77c\\ubcf4 \\uad6c\\ub3c5\\uc2e0\\uccad\\ud558\\uae30] - Copyrights \\u24d2 \\uc870\\uc120\\uc77c\\ubcf4 & chosun.com, \\ubb34\\ub2e8 \\uc804\\uc7ac \\ubc0f \\uc7ac\\ubc30\\ud3ec \\uae08\\uc9c0 -\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['articles'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "c3h_G9vprbpk",
        "outputId": "a8c7dfb5-8209-4ee6-ab3d-c9d266fcb659"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"게티이미지뱅크 콩나물(사진)은 대두를 발아시켜 뿌리를 자라게 한 것이다. 동의보감에 따르면 콩나물은 온 몸이 무겁고 저리거나 근육과 뼈가 아플 때 도움이 되고 제반 염증을 억제하는 효과가 뛰어나다고 돼 있다.콩나물에 들어있는 식물 단백질인 '아스파라긴산'은 1806년 프랑의 과학자 아스파라거스가 발견해 이름이 붙여졌다. 아스파라긴산은 암모니아 대사를 촉진해 독소를 흡수하고 혈액을 통해 제거하므로 간 건강에 도움이 된다. 이 때문에 숙취해소에 탁월한 효과를 보인다. 또 콩팥의 기능을 돕고 요산배설을 촉진시킴과 동시에 신경통이나 류머티즘에 효과를 보인다.콩나물은 대두 상태일 때는 비타민이 없지만 발아하는 과정에서 합성돼 비타민C가 풍부해진다. 비타민C는 피부를 맑고 투명하게 가꿔주고 면역력을 높여준다. 하지만 콩나물을 조리하는 과정에서 비타민C가 파괴되기 때문에 가볍게 조리해 섭취하는 게 좋다.정명진 의학전문기자 pompom@fnnews.com 정명진 기자 ▶ 세상의 모든 골 때리는 이야기 'fn파스'▶ 속보이는 연예뉴스 fn스타 ※ 저작권자 ⓒ 파이낸셜뉴스. 무단 전재-재배포 금지\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_data = []\n",
        "\n",
        "# 불용어 정의\n",
        "stopwords = ['을','게티이미지뱅크', '부터', '까지' '적', '의','가','이','은','들',\n",
        "             '는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다',\n",
        "             '무단','전재재배포', '금지']\n",
        "\n",
        "# 형태소 분석기 OKT를 사용한 토큰화 작업 (다소 시간 소요)\n",
        "okt = Okt()\n",
        "\n",
        "for sentence in tqdm(train_data['articles']):\n",
        "    tokenized_sentence = okt.nouns(sentence)\n",
        "    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords] # 불용어 제거\n",
        "    stopwords_removed_sentence = [ i  for i in stopwords_removed_sentence if len(i) > 1]\n",
        "    tokenized_data.append(stopwords_removed_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g42lRP2qkItb",
        "outputId": "1abf4dde-28e6-4b35-f12b-a505bb77e993"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [00:55<00:00,  7.20it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenized_data)\n",
        "print( tokenized_data[10] )\n",
        "train_data['articles'][10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "id": "O2yayrQam2kG",
        "outputId": "53f1f450-c09a-4b2d-8dd8-61705bc80041"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['새해', '금주', '목표', '성공', '무작정', '단기', '목표', '먼저', '기간', '점차', '식이', '도움', '사진', '클립아트', '코리아', '회사원', '김모', '새해', '건강', '위해', '결심', '문제', '결심', '반복', '고혈압', '진단', '금주', '목표', '달도', '올해', '회사', '업무', '조직', '개편', '스트레스', '금주', '자신감', '금주', '고민', '김씨', '새해', '금주', '결심', '사람', '작심삼일', '경우', '금주', '성공', '확률', '다사', '중앙', '병원', '정신건강', '의학과', '허성', '원장', '무작정', '방법', '오히려', '스트레스', '가중', '기간', '정해', '서서히', '음주', '빈도', '계획', '오늘', '하루', '생각', '금주', '기간', '일주일', '단위', '차차', '금주', '확률', '회사', '금주', '계획', '알리', '회식', '단호', '거절', '원장', '술잔', '시작', '중단', '일반', '우리나라', '음주', '문화', '이기', '때문', '자신', '금주', '계획', '선포', '실천', '공유', '방법', '실제', '영국', '새해', '금주', '각오', '서로', '실천', '독려', '드라이', '재뉴', '캠페인', '매년', '음주', '예방', '자선단체', '실시', '주최', '작년', '참가', '동안', '완전', '금주', '사람', '캠페인', '음주', '빈도', '일일', '주량', '감소', '대체', '즐거움', '원장', '알코올', '스트레스', '상황', '발생', '습관', '금주', '성공', '좌우', '만큼', '자신', '운동', '문화생활', '스트레스', '비책', '각오', '구체', '계획', '실천', '불구', '금주', '반복', '혼자', '상황', '이기', '때문', '지역', '중독', '관리', '센터', '문병원', '치료', '프로그램', '고려', '이해', '헬스', '조선', '기자', '국내', '최고', '명의', '누구', '대표', '건강', '사이트', '헬스', '조선닷컴', '바로가기']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'새해 금주 목표 성공을 위해서는 무작정 술을 참기보다 단기 목표를 먼저 세우고 기간을 점차 늘려가는 식이 도움이 된다./사진=클립아트코리아회사원 김모(45)씨는 새해를 맞아 건강을 위해 술을 끊기로 결심했다. 문제는 5년째 결심만 반복된다는 것이다. 5년 전 고혈압 진단을 받은 뒤부터 금주를 목표로 했지만 늘 한 달도 못 가 실패했다. 올해도 회사에서 주어진 새로운 업무와 조직 개편으로 스트레스를 받고 있어 금주에 성공할 것이라는 자신감이 없었다. 어떻게 해야 금주에 성공할지 고민이 됐다.김씨처럼 새해 금주를 결심하는 사람이 많지만 작심삼일로 끝나는 경우가 많다. 금주 성공 확률을 높이려면 어떻게 해야 할까?다사랑중앙병원 정신건강의학과 허성태 원장은 \"무작정 술을 마시지 않고 참는 방법은 오히려 스트레스를 가중시킬 수 있다\"며 \"기간을 정해 서서히 음주 빈도를 줄이는 등의 계획이 필요하다\"고 말했다. 이어 그는 \"오늘 하루만 마시지 말자는 생각으로 금주하고, 이 기간을 일주일, 한 달 단위로 차차 늘리면 금주에 성공할 확률이 높아진다\"고 덧붙였다.단, 회사에서는 금주 계획을 알리고 회식 중 첫 잔부터 단호하게 거절하는 게 좋다. 허 원장은 \"술잔을 한 번 받기 시작하면 중단하기 어려운 것이 일반적인 우리나라 음주 문화이기 때문\"이라고 말했다.SNS에 자신의 금주 계획을 선포하고 어떻게 실천하는지 공유하는 것도 방법이다. 실제 영국에서는 새해가 되면 SNS에 한 달간의 금주 각오를 올리고 서로 실천을 독려하며 1월 한 달 술을 끊는 \\'드라이 재뉴어리\\' 캠페인이 매년 음주예방 자선단체에 의해 실시되고 있다. 주최 측에 따르면 작년에 400만명이 참가했고, 1월 한 달 동안 ‘완전 금주’에 성공한 사람들은 캠페인 후 음주 빈도와 일일 음주량이 감소했다.술을 대체할 즐거움을 찾는 것도 중요하다. 허 원장은 “알코올에 민감해진 뇌는 스트레스 상황이 발생하면 습관적으로 술을 찾게 할 수 있다\"며 “술 없이도 즐거울 수 있다는 것을 깨닫는 것이 금주 성공을 좌우하는 만큼 자신에게 맞는 운동이나 문화생활과 등 건강한 스트레스 대비책을 찾아야 한다”고 말했다. 이어 그는 \"술을 끊겠다는 각오와 구체적인 계획 실천에도 불구하고 금주에 반복해서 실패하면 혼자서 술을 끊기 어려운 상황이기 때문에 지역 내 중독관리지원센터나 전문병원 치료 프로그램을 고려해보라”고 덧붙였다./ 이해나 헬스조선 기자▶국내 최고 명의 590명은 누구일까?▶대표 건강 사이트 헬스조선닷컴 바로가기'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. lda 적용"
      ],
      "metadata": {
        "id": "01aWFQA_u4yX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import corpora\n",
        "dictionary = corpora.Dictionary(tokenized_data) #사전 구성\n",
        "corpus = [dictionary.doc2bow(text) for text in tokenized_data]  #Bag of Words 구성\n",
        "corpus[1] # 수행된 결과에서 두번째 문서 출력, 첫번째 문서의 인덱스는 0"
      ],
      "metadata": {
        "id": "L7LRwvqhPTCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "NUM_TOPICS = 10\n",
        "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
        "topics = ldamodel.print_topics(num_words=10)\n",
        "for topic in topics:\n",
        "    print(topic)"
      ],
      "metadata": {
        "id": "HALjlGbdPZLi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bef12a67-0cfc-44e2-b026-904e349d847e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, '0.009*\"기술\" + 0.007*\"시장\" + 0.007*\"한국\" + 0.006*\"더블\" + 0.006*\"지난해\" + 0.006*\"국내\" + 0.005*\"기자\" + 0.005*\"스마트폰\" + 0.005*\"판매\" + 0.004*\"산업\"')\n",
            "(1, '0.006*\"암호\" + 0.006*\"비트코인\" + 0.005*\"기술\" + 0.005*\"블록\" + 0.005*\"체인\" + 0.005*\"리움\" + 0.004*\"앵커\" + 0.004*\"기자\" + 0.004*\"포크\" + 0.004*\"인터뷰\"')\n",
            "(2, '0.022*\"간송\" + 0.009*\"게임\" + 0.009*\"전시\" + 0.008*\"미술관\" + 0.005*\"맥주\" + 0.005*\"서울\" + 0.005*\"미술\" + 0.005*\"문화재\" + 0.005*\"일본\" + 0.005*\"기자\"')\n",
            "(3, '0.006*\"사람\" + 0.005*\"발레\" + 0.005*\"자신\" + 0.005*\"우리\" + 0.004*\"프린팅\" + 0.004*\"시간\" + 0.004*\"제품\" + 0.004*\"때문\" + 0.003*\"봄여름가을겨울\" + 0.003*\"사랑\"')\n",
            "(4, '0.032*\"게임\" + 0.028*\"넥슨\" + 0.021*\"대표\" + 0.014*\"매각\" + 0.012*\"업계\" + 0.010*\"국내\" + 0.009*\"중국\" + 0.008*\"인수\" + 0.007*\"텐센트\" + 0.007*\"김정주\"')\n",
            "(5, '0.008*\"중국\" + 0.007*\"지구\" + 0.007*\"탐사\" + 0.007*\"우주\" + 0.006*\"착륙\" + 0.005*\"미국\" + 0.005*\"기자\" + 0.004*\"마곡사\" + 0.004*\"라인\" + 0.004*\"지난해\"')\n",
            "(6, '0.019*\"서비스\" + 0.011*\"콘텐츠\" + 0.010*\"시장\" + 0.010*\"택시\" + 0.008*\"사업\" + 0.008*\"텔레콤\" + 0.008*\"지상파\" + 0.007*\"국내\" + 0.007*\"플랫폼\" + 0.005*\"카카오\"')\n",
            "(7, '0.008*\"환자\" + 0.008*\"애플\" + 0.006*\"병원\" + 0.006*\"치료\" + 0.005*\"중국\" + 0.005*\"발생\" + 0.005*\"질환\" + 0.005*\"위험\" + 0.005*\"경우\" + 0.005*\"사람\"')\n",
            "(8, '0.009*\"노비\" + 0.008*\"돼지\" + 0.007*\"치킨\" + 0.006*\"경우\" + 0.005*\"최고\" + 0.004*\"때문\" + 0.004*\"통증\" + 0.004*\"관절\" + 0.004*\"왕나비\" + 0.004*\"나비\"')\n",
            "(9, '0.007*\"전자\" + 0.006*\"기술\" + 0.006*\"시장\" + 0.005*\"장비\" + 0.005*\"사람\" + 0.005*\"네트워크\" + 0.004*\"교회\" + 0.004*\"치료\" + 0.004*\"바이오\" + 0.004*\"세포\"')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ldamodel_mc = gensim.models.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=10)\n",
        "topics = ldamodel_mc.print_topics(num_words=10)\n",
        "for topic in topics:\n",
        "    print(topic)"
      ],
      "metadata": {
        "id": "Z89w0WXpzVOy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dffd172-6bd8-497e-cfa0-b83f59736f80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, '0.016*\"서비스\" + 0.012*\"콘텐츠\" + 0.012*\"택시\" + 0.009*\"지상파\" + 0.009*\"텔레콤\" + 0.007*\"시장\" + 0.006*\"국내\" + 0.006*\"옥수수\" + 0.006*\"플랫폼\" + 0.005*\"대표\"')\n",
            "(1, '0.012*\"전자\" + 0.009*\"시장\" + 0.009*\"기술\" + 0.007*\"판매\" + 0.007*\"지난해\" + 0.006*\"시스템\" + 0.005*\"차량\" + 0.005*\"전망\" + 0.005*\"공개\" + 0.005*\"자동차\"')\n",
            "(2, '0.012*\"비트코인\" + 0.006*\"채굴\" + 0.006*\"통영\" + 0.004*\"화폐\" + 0.004*\"사람\" + 0.004*\"암호\" + 0.003*\"도전\" + 0.003*\"기자\" + 0.003*\"사진\" + 0.003*\"사랑\"')\n",
            "(3, '0.011*\"애플\" + 0.006*\"아이폰\" + 0.005*\"중국\" + 0.005*\"경우\" + 0.005*\"때문\" + 0.005*\"매출\" + 0.005*\"기자\" + 0.004*\"경제\" + 0.004*\"사람\" + 0.003*\"미국\"')\n",
            "(4, '0.006*\"환자\" + 0.006*\"중국\" + 0.005*\"우주\" + 0.005*\"지구\" + 0.005*\"탐사\" + 0.005*\"미국\" + 0.004*\"병원\" + 0.004*\"개발\" + 0.004*\"교수\" + 0.004*\"착륙\"')\n",
            "(5, '0.008*\"리움\" + 0.007*\"포크\" + 0.007*\"하드\" + 0.005*\"치킨\" + 0.005*\"마곡사\" + 0.005*\"암호\" + 0.004*\"영상\" + 0.004*\"기자\" + 0.004*\"유성우\" + 0.003*\"최고\"')\n",
            "(6, '0.007*\"미세먼지\" + 0.006*\"사람\" + 0.006*\"축제\" + 0.005*\"때문\" + 0.005*\"우리\" + 0.004*\"뉴스\" + 0.004*\"기자\" + 0.004*\"쇼팽\" + 0.003*\"산천어\" + 0.003*\"프레데릭\"')\n",
            "(7, '0.027*\"게임\" + 0.020*\"넥슨\" + 0.016*\"대표\" + 0.010*\"업계\" + 0.010*\"매각\" + 0.008*\"국내\" + 0.008*\"중국\" + 0.007*\"산업\" + 0.006*\"인수\" + 0.006*\"회사\"')\n",
            "(8, '0.017*\"간송\" + 0.007*\"전시\" + 0.006*\"한국\" + 0.006*\"미술관\" + 0.005*\"기술\" + 0.004*\"서울\" + 0.004*\"기자\" + 0.004*\"미술\" + 0.004*\"문화재\" + 0.004*\"국보\"')\n",
            "(9, '0.009*\"발생\" + 0.008*\"치료\" + 0.006*\"증상\" + 0.006*\"환자\" + 0.006*\"부작용\" + 0.005*\"타미플루\" + 0.005*\"병원\" + 0.005*\"위험\" + 0.004*\"위암\" + 0.004*\"이상\"')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from gensim.models.ldamodel import LdaModel\n",
        "from gensim.models.callbacks import CoherenceMetric\n",
        "from gensim import corpora\n",
        "from gensim.models.callbacks import PerplexityMetric\n",
        "import logging\n",
        "import pickle\n",
        "import pyLDAvis.gensim_models\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "zlBXkSazRXxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coherence_values = []\n",
        "model_list = []\n",
        "iters = [6,10, 14, 18, 22, 26]\n",
        "\n",
        "for num_topics in iters:\n",
        "     model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, passes=15)\n",
        "     model_list.append(model)\n",
        "     coherencemodel = CoherenceModel(model=model, texts=tokenized_data, dictionary=dictionary, coherence='c_v')\n",
        "     coherence_values.append(coherencemodel.get_coherence())\n"
      ],
      "metadata": {
        "id": "U7kSdFPRRnoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, len(iters)):\n",
        "  print(model_list[i], coherence_values[i])  #topic num별로 coherence 가 높은 것을 찾기"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fZ56k7dRqqh",
        "outputId": "e1a7282f-2931-4bc1-b350-eb2aa6166918"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LdaModel<num_terms=13790, num_topics=6, decay=0.5, chunksize=2000> 0.4248112839257618\n",
            "LdaModel<num_terms=13790, num_topics=10, decay=0.5, chunksize=2000> 0.4263626359367646\n",
            "LdaModel<num_terms=13790, num_topics=14, decay=0.5, chunksize=2000> 0.4559145558314543\n",
            "LdaModel<num_terms=13790, num_topics=18, decay=0.5, chunksize=2000> 0.43692319374900235\n",
            "LdaModel<num_terms=13790, num_topics=22, decay=0.5, chunksize=2000> 0.43929834998461176\n",
            "LdaModel<num_terms=13790, num_topics=26, decay=0.5, chunksize=2000> 0.47049969713663603\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyLDAvis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtUSrsXlwjx1",
        "outputId": "2fabb007-2022-42d2-cb24-995608d52de4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyLDAvis\n",
            "  Downloading pyLDAvis-3.4.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: numpy>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.13.1)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (2.2.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.5.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (3.1.6)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (2.10.2)\n",
            "Collecting funcy (from pyLDAvis)\n",
            "  Downloading funcy-2.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.6.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (4.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (80.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.17.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim->pyLDAvis) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim->pyLDAvis) (1.17.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->pyLDAvis) (3.0.2)\n",
            "Downloading pyLDAvis-3.4.1-py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading funcy-2.0-py2.py3-none-any.whl (30 kB)\n",
            "Installing collected packages: funcy, pyLDAvis\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [pyLDAvis]\n",
            "\u001b[1A\u001b[2KSuccessfully installed funcy-2.0 pyLDAvis-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyLDAvis.gensim_models\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "from pprint import pprint\n",
        "\n",
        "# 예제 문서\n",
        "documents = [\n",
        "    \"사과 바나나 오렌지\",\n",
        "    \"컴퓨터 키보드 마우스\",\n",
        "    \"사과 오렌지\",\n",
        "    \"키보드 마우스 모니터\",\n",
        "    \"사과 컴퓨터 오렌지\"\n",
        "]\n",
        "\n",
        "# 전처리: 단어 분할\n",
        "texts = [doc.split() for doc in documents]\n",
        "\n",
        "# Dictionary 및 Corpus 생성\n",
        "dictionary = corpora.Dictionary(texts)\n",
        "corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "\n",
        "# LDA 모델 학습\n",
        "lda_model = gensim.models.LdaModel(\n",
        "    corpus=corpus,\n",
        "    id2word=dictionary,\n",
        "    num_topics=2,\n",
        "    random_state=42,\n",
        "    passes=10,\n",
        "    per_word_topics=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "drvWKY2-Lf4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3, 트랜스포머"
      ],
      "metadata": {
        "id": "7bWYlQbS06ou"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gy5b5hDEwiVz",
        "outputId": "d9f1497a-0882-4874-d438-5fdc34b73ac0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m98.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 허깅페이스 활용"
      ],
      "metadata": {
        "id": "uIVySAb6xRby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# 감성 분석 파이프라인 생성\n",
        "classifier = pipeline(\"sentiment-analysis\")   # 최적화된 사전 학습 모델을 자동으로 불러\n",
        "\n",
        "# 테스트 문장\n",
        "sentences = [\n",
        "    \"I love this movie, it was fantastic!\",\n",
        "    \"I hate waiting in long lines.\",\n",
        "    \"The product was okay, but could be better.\"\n",
        "]\n",
        "\n",
        "# 결과 출력\n",
        "for sentence in sentences:\n",
        "    result = classifier(sentence)[0]\n",
        "    print( sentence, result[\"label\"], result[\"score\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "td2Ja1bPwxlp",
        "outputId": "a14fb74d-5dfe-4687-fbb5-d6819d4d5338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I love this movie, it was fantastic! POSITIVE 0.9998763799667358\n",
            "I hate waiting in long lines. NEGATIVE 0.9968921542167664\n",
            "The product was okay, but could be better. NEGATIVE 0.9422469735145569\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classifier.model.name_or_path)"
      ],
      "metadata": {
        "id": "EetJcl6Y0Jyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모형 선택"
      ],
      "metadata": {
        "id": "gIa1bjK0xWD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")"
      ],
      "metadata": {
        "id": "Kk2vszKu0W-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification  #파라미터, layer 출력 등 직접 조작 가능, logits 직접 받아서 해석해야 함, 모델 튜닝, 커스텀 학습 등 심화 작업\n",
        "import torch\n",
        "\n",
        "# 사전 학습된 모델과 토크나이저 로딩\n",
        "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)   #모델 이름에 맞는 토크나이저 자동 로드 (문장 → 숫자)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)    #분류 작업에 맞게 사전학습 모델 + 분류기 로드\n",
        "\n",
        "# 입력 문장\n",
        "text = \"I really enjoy using Hugging Face models.\"\n",
        "\n",
        "# 토큰화로 텐서 변환\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "\n",
        "# 예측\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
        "    predicted = torch.argmax(probs)\n",
        "\n",
        "print(\"Predicted class:\", predicted.item())\n",
        "print(\"Probabilities:\", probs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240,
          "referenced_widgets": [
            "6ee41c038df846b781206655264d206a",
            "85789a483ab04127882c87cb1a6e61c6",
            "be9e91f608014694a2da348a9637ad96",
            "c832fcbf135c4a9f91c82f4b8adc5423",
            "e162acde8fa740a99a174c6773212af3",
            "88fd7c7165094282804a824ff1301d34",
            "55e7d78b18ff497aa6689fbb2ab0b420",
            "aed33576611c4b018882d20dfb8a964e",
            "ed798cc516aa48c6af80306b6932abae",
            "9795084cec8c4e378e3614ff11884ed0",
            "b015afaed76a4e6a82afbb0a3823960a",
            "6f9d231f5934497a80f84710c8c1427d",
            "bc64c42dcec940308e8edfd3550df377",
            "908907d2e1af4c7191e2c7745e0e2e85",
            "b7971a36ed264588bd3d13927cc4a07f",
            "b2aff824fa994218a42c00b8151b958b",
            "ba13bd5214e74cf39ba826ed62ee65d0",
            "75f51a6cbca54785a6ffc983fd1ae801",
            "2b5180983347431bbc2ced764cbafcf7",
            "b49f1ba55f41499a9a5ce6854cded909",
            "888aad88eefc4e41b7103f21908fe213",
            "99d3643c812942fa907c2518ee9fb39e",
            "4699cbfa0f2b414b9cc39dda21f74d40",
            "318a7849fd8d45e38e3d45922c4d4acb",
            "279324e73d1044adb507678e23c32cea",
            "b7abb943b11440c5ae1ba8c385a9e9fd",
            "d1ed2bcf07274476a2eee7369d073792",
            "5b8b0a18c9a3447384382154660a9fbb",
            "0bb8255ae84e469197f18c67fe302f43",
            "84f401abc6c34ac78aff1746802d7e1f",
            "991884169f8e498b88b8cffacc1d4104",
            "4640dc41371a4ceab968b18146044d4e",
            "f82d10ff1e914fd58cbc0bdcd7421551",
            "2ac3c9f3418142938c0b0c8c4751d99f",
            "168145ab67e14c5b9dacfb693b60beb6",
            "85206c9fa3bd46ea80c65415d90d74d7",
            "ffaccebfc56746ad9e0878c7df8d4ff4",
            "cee114db04124ad3b49332450842d2ee",
            "cb69109471304af381487648a9152d0a",
            "66bdb46811a840c1b142e5179f226c29",
            "fa72441c5b7445c3824a533b22a5f38f",
            "708ac494ad06454582fd636904bc419f",
            "07daa7492eb14576bdadeb3e55d6d46c",
            "b40e522499d542cb82ef07d20daf3ebd"
          ]
        },
        "id": "9Ueu2L47wxoN",
        "outputId": "d99d8322-293a-4f5f-bbd2-9da2d7807ed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ee41c038df846b781206655264d206a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f9d231f5934497a80f84710c8c1427d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4699cbfa0f2b414b9cc39dda21f74d40"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ac3c9f3418142938c0b0c8c4751d99f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: 1\n",
            "Probabilities: tensor([[0.0018, 0.9982]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 한글"
      ],
      "metadata": {
        "id": "dfrqBAryxKmr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " - beomi/KcELECTRA-base\t한국어 일상 언어 기반 모델\n",
        " - monologg/kobert\tSKT KoBERT\n",
        " - snunlp/KR-FinBERT-SC\t금융 텍스트 감성 분석\n",
        " - nlp04/korean-sentiment\t네이버 영화리뷰 감정 분류"
      ],
      "metadata": {
        "id": "HKsBioJmxMAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "\n",
        "# 모델 및 토크나이저 불러오기\n",
        "model_name = \"monologg/kobert\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"snunlp/KR-FinBERT-SC\")  # 감성분석 fine-tuned 버전 예시\n",
        "\n",
        "# 파이프라인 구성\n",
        "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "# 입력 문장\n",
        "texts = [\n",
        "    \"이 제품 정말 좋아요!\",\n",
        "    \"서비스가 최악이었어요.\",\n",
        "    \"가격은 비싼데 성능은 별로예요.\"\n",
        "]\n",
        "\n",
        "# 결과 출력\n",
        "for text in texts:\n",
        "    result = classifier(text)[0]\n",
        "    print(text, result[\"label\"], result[\"score\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6ZbfDIawxq0",
        "outputId": "f0581fdd-c0a6-4baa-c87e-15fe9f513aab"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The repository `monologg/kobert` contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/monologg/kobert.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] y\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "이 제품 정말 좋아요! neutral 0.9914306998252869\n",
            "서비스가 최악이었어요. neutral 0.8165387511253357\n",
            "가격은 비싼데 성능은 별로예요. neutral 0.8831380009651184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "\n",
        "# 모델 및 토크나이저\n",
        "model_name = \"klue/bert-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"klue/bert-base\")\n",
        "\n",
        "# 감성 분석 파이프라인 구성 (주의: 이 모델은 fine-tuned 안됨)\n",
        "classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "# 입력 예시\n",
        "text = \"이 영화는 정말 감동적이었다.\"\n",
        "\n",
        "# 예측\n",
        "result = classifier(text)[0]\n",
        "print(text, result[\"label\"], result[\"score\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_8k-TMYwxtJ",
        "outputId": "67e5fc11-83a4-4756-a29a-0c59090c78d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "이 영화는 정말 감동적이었다. LABEL_1 0.5664965510368347\n"
          ]
        }
      ]
    }
  ]
}